{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## large"
      ],
      "metadata": {
        "id": "x4qNYWKBh-j8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !gdown --id \"1W29UzDy0KUK4jpMPeSes9LN9QPRcvj3p\" -O /content/your_data.zip\n",
        "\n",
        "# !unzip /content/your_data.zip -d /content/extracted_data"
      ],
      "metadata": {
        "id": "1J_ePALYiBBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## small"
      ],
      "metadata": {
        "id": "NkZnXFwHh8TV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !gdown --id \"1Vh9rV1ctXVCrg3Zw0nVbUsvjtt5Re5qK\" -O /content/your_data.zip\n",
        "\n",
        "# !unzip /content/your_data.zip -d /content/extracted_data"
      ],
      "metadata": {
        "id": "Va_0bHQ76znp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test"
      ],
      "metadata": {
        "id": "wAVeSxiogpiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !gdown --id \"1DAYgTgOFli8rC-i-LM4k72D88waI7cJh\" -O /content/your_data.zip\n",
        "\n",
        "# !unzip /content/your_data.zip -d /content/extracted_data"
      ],
      "metadata": {
        "id": "q02A9wF3grJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "1wFQZPHShC_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score"
      ],
      "metadata": {
        "id": "CGEpaX1sHV20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edd3668a-7aaf-4ba5-ae4e-f834e7017ef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.25.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "from torchvision.models import resnet152\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "from rouge_score import rouge_scorer"
      ],
      "metadata": {
        "id": "HxOuikYe7ZmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read data"
      ],
      "metadata": {
        "id": "sorQtIVWhFlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data = pd.read_csv('./train.csv')\n",
        "data = pd.read_csv('./train_small.csv')\n",
        "# data = pd.read_csv('./test.csv')"
      ],
      "metadata": {
        "id": "LVKCqxG7_1gG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load model"
      ],
      "metadata": {
        "id": "qUxT8NR1hH7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "bert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "resnet_model = resnet152(pretrained=True)\n",
        "resnet_model.eval()"
      ],
      "metadata": {
        "id": "xhy6ealPAyv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "yqQoHnOwhK3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image)\n",
        "    return image\n",
        "\n",
        "def encode_text(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
        "    outputs = bert_model(**inputs)\n",
        "    return outputs.last_hidden_state.squeeze(0)"
      ],
      "metadata": {
        "id": "y-ZQqp0zAcTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature extraction\n"
      ],
      "metadata": {
        "id": "OeHcVQ21hPSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_process_images(file_name, image_folder):\n",
        "    pattern = os.path.join(image_folder, f\"{file_name}_*.jpg\")\n",
        "    image_paths = glob.glob(pattern)\n",
        "    if not image_paths:\n",
        "        return torch.zeros((1, 2048))\n",
        "    images = [preprocess_image(img_path) for img_path in image_paths]\n",
        "    images_tensor = torch.stack(images)\n",
        "    with torch.no_grad():\n",
        "        features = resnet_model(images_tensor)\n",
        "    return features.mean(dim=0).unsqueeze(0)"
      ],
      "metadata": {
        "id": "vUcEjTarSr5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Model"
      ],
      "metadata": {
        "id": "qo1BdbqXhU7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=1, seq_len=20):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, combined_features, hidden=None):\n",
        "        if combined_features.dim() == 2:\n",
        "            combined_features = combined_features.unsqueeze(1).repeat(1, self.seq_len, 1)\n",
        "        output, hidden = self.lstm(combined_features, hidden)\n",
        "        output = self.fc(output.reshape(-1, hidden_dim))\n",
        "        return output\n",
        "\n",
        "class SummaryModel(nn.Module):\n",
        "    def __init__(self, text_input_dim, image_input_dim, decoder_hidden_dim, vocab_size, seq_len=20):\n",
        "        super(SummaryModel, self).__init__()\n",
        "        self.decoder_input_dim = text_input_dim + image_input_dim\n",
        "        self.decoder = Decoder(self.decoder_input_dim, decoder_hidden_dim, vocab_size, seq_len=seq_len)\n",
        "\n",
        "    def forward(self, text_features, image_features):\n",
        "        if text_features.dim() == 1:\n",
        "            text_features = text_features.unsqueeze(0)\n",
        "        if image_output.dim() == 1:\n",
        "            image_features = image_features.unsqueeze(0)\n",
        "        combined_features = torch.cat([text_features, image_features], dim=1)\n",
        "        outputs = self.decoder(combined_features)\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "gCEOG2nNOAgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "sdS2wqX6hZaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 30522\n",
        "model = SummaryModel(text_input_dim=768, image_input_dim=2048, decoder_hidden_dim=512, vocab_size=30522, seq_len=20)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "Szr7EwduhaT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('./train_small.csv')\n",
        "image_folder = '/content/extracted_data/img_small/'"
      ],
      "metadata": {
        "id": "F_EjfAwZz2wL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(model, text, file_name, image_folder):\n",
        "    text_feat = encode_text(text).unsqueeze(0)\n",
        "    image_feat = load_and_process_images(file_name, image_folder)\n",
        "    if image_feat.dim() == 1:\n",
        "        image_feat = image_feat.unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        output = model(text_feat, image_feat)\n",
        "    summary_ids = output.argmax(dim=-1)\n",
        "    return tokenizer.decode(summary_ids.squeeze(), skip_special_tokens=True)\n",
        "\n",
        "def find_most_relevant_image(file_name, summary):\n",
        "    base_path = f'{image_folder}/{file_name}_'\n",
        "    text_features = encode_text(summary).squeeze().numpy()\n",
        "    best_image = None\n",
        "    best_similarity = -1\n",
        "    i = 1\n",
        "    while os.path.exists(f'{base_path}{i}.jpg'):\n",
        "        img_path = f'{base_path}{i}.jpg'\n",
        "        image_features = preprocess_image(img_path).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            image_features = resnet_model(image_features).squeeze().numpy()\n",
        "        similarity = cosine_similarity([text_features], [image_features])[0][0]\n",
        "        if similarity > best_similarity:\n",
        "            best_similarity = similarity\n",
        "            best_image = img_path\n",
        "        i += 1\n",
        "    return best_image"
      ],
      "metadata": {
        "id": "afDbXnTdSwwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rouge"
      ],
      "metadata": {
        "id": "hlq3Htpr9CAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['generated_summary'] = data.apply(lambda row: generate_summary(model, row['article'], row['fileName'], image_folder), axis=1)\n",
        "data['most_relevant_image'] = data.apply(lambda row: find_most_relevant_image(row['fileName'], row['generated_summary']), axis=1)\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "data['rouge_scores'] = data.apply(lambda row: scorer.score(row['summary'], row['generated_summary']), axis=1)\n",
        "\n",
        "print(data[['generated_summary', 'most_relevant_image', 'rouge_scores']])"
      ],
      "metadata": {
        "id": "Y6wUemO0lOi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cosine similarity & Euclidean distance"
      ],
      "metadata": {
        "id": "swKmJ5yX9GA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def calculate_similarity_and_distance(row):\n",
        "    text_features = encode_text(row['generated_summary']).detach().numpy()\n",
        "\n",
        "    image_path = row['most_relevant_image']\n",
        "    image = preprocess_image(image_path)\n",
        "    image = image.unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        image_features = resnet_model(image).squeeze(0).numpy()\n",
        "\n",
        "    cosine_sim = cosine_similarity([text_features], [image_features])[0][0]\n",
        "\n",
        "    euclidean_dist = np.linalg.norm(text_cent_features - image_features)\n",
        "\n",
        "    return pd.Series([cosine_sim, euclidean_dist], index=['cosine_similarity', 'euclidean_distance'])\n",
        "\n",
        "data[['cosine_similarity', 'euclidean_distance']] = data.apply(calculate_similarity_and_distance, axis=1)\n",
        "\n",
        "print(data[['generated_summary', 'most_relevant_image', 'cosine_similarity', 'euclidean_distance']])"
      ],
      "metadata": {
        "id": "6fSYRq_b9p07"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}